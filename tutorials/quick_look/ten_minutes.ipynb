{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fugue in 10 minutes\n",
    "\n",
    "All questions are welcome in the Slack channel.\n",
    "\n",
    "[![Slack Status](https://img.shields.io/badge/slack-join_chat-white.svg?logo=slack&style=social)](http://slack.fugue.ai)\n",
    "\n",
    "This is a short introduction to [Fugue](https://github.com/fugue-project/fugue) geared towards new users. The Fugue project aims to make big data effortless by accelerating iteration speed and providing a simpler interface for users to utilize distributed computing engines.\n",
    "\n",
    "This tutorial covers the Python interface only. For SQL, check the FugueSQL in 10 minutes section.\n",
    "\n",
    "Fugue's intended audience consists of but is not limited to:\n",
    "1. Data scientists who need to bring business logic written in Python or Pandas to bigger datasets\n",
    "2. Data practitioners looking to parallelize existing code with distributed computing\n",
    "3. Data teams that want to reduce the maintenance and testing of boilerplate Spark code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "For this tutorial, we firstly need to run through some quick setup steps in order to instantiate a Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/18 12:01:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bringing a function to Spark or Dask\n",
    "\n",
    "The simplest way to scale pandas based code to Spark or Dask is with the `transform()` function. With the addition of this modest wrapper, we can bring existing Pandas and Python code to distributed execution with minimal refactoring. The `transform()` function also provides quality of life enhancements that can eliminate boilerplate code for users.\n",
    "\n",
    "\n",
    "\n",
    "Let's quickly demonstrate how this concept can be applied to a typical user story. In the following code snippets illustrated below we will train a model using scikit-learn and pandas. Then we will perform predictions using this model whilst achieving parallelization by supplying a Spark execution engine as an argument in Fugue's `transform()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = pd.DataFrame({\"x_1\": [1, 1, 2, 2], \"x_2\":[1, 2, 2, 3]})\n",
    "y = np.dot(X, np.array([1, 2])) + 3\n",
    "reg = LinearRegression().fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training our model, we then wrap it in a `predict()` function. Bear in mind that this function is still written in pandas making it easy to test on the `input_df` that we create. Wrapping our model in `predict()` will allow us to bridge execution to Spark or Dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x_1  x_2  predicted\n",
       "0    3    3       12.0\n",
       "1    4    3       13.0\n",
       "2    6    6       21.0\n",
       "3    6    6       21.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define our predict function\n",
    "def predict(df: pd.DataFrame, model: LinearRegression) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function to predict results using a pre-built model\n",
    "    \"\"\"\n",
    "    return df.assign(predicted=model.predict(df))\n",
    "\n",
    "# create test data\n",
    "input_df = pd.DataFrame({\"x_1\": [3, 4, 6, 6], \"x_2\":[3, 3, 6, 6]})\n",
    "\n",
    "# test the predict function\n",
    "predict(input_df.copy(), reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this is where it starts to get interesting, let's bring the same code defined above to Spark using Fugue `transform()`. We take our dataframe and apply the `predict()` function to it using either one of the Pandas, Spark, or Dask engines. The `transform()` parameters will be explained in detail later on, but for now, notice how we made no modifications to the `predict()` function in order to switch the execution from Pandas to Spark. All we have to do is pass in the `SparkSession` as the engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:=================================================>        (6 + 1) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---------+\n",
      "|x_1|x_2|predicted|\n",
      "+---+---+---------+\n",
      "|  3|  3|     12.0|\n",
      "|  4|  3|     13.0|\n",
      "|  6|  6|     21.0|\n",
      "|  6|  6|     21.0|\n",
      "+---+---+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# import Fugue\n",
    "from fugue import transform\n",
    "\n",
    "# create a spark dataframe\n",
    "sdf = spark.createDataFrame(input_df)\n",
    "\n",
    "# use Fugue transform to switch exection to spark\n",
    "result = transform(\n",
    "    df=sdf,\n",
    "    using=predict,\n",
    "    schema=\"*,predicted:double\",\n",
    "    params=dict(model=reg),\n",
    "    engine=spark\n",
    ")\n",
    "\n",
    "# display results\n",
    "print(type(result))\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `transform()` function provides much more flexibility for users than what we have just described above. This is just a simple use case designed to give you a flavour of what Fugue has to offer. For this example, the `transform()` function took in the following arguments:\n",
    "\n",
    "* df     - input DataFrame (can be a pandas, Spark, or Dask DataFrame)\n",
    "* using  - a Python function with valid input and output types\n",
    "* schema - output schema of the operation\n",
    "* params - a dictionary of parameters to pass in the function\n",
    "* engine - the execution engine to run the operation on pandas, Spark, or Dask \n",
    "\n",
    "We will delve into these variables in more detail later on, this will include an explanation of the roles that `type annotations` and `schema` play. For now, the most important thing to discuss is the engine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution Engines\n",
    "\n",
    "Because we supplied the `spark` variable as the engine, the `predict()` function will be applied on the Spark DataFrame `sdf` using Spark. Similarly, passing a Dask Client as the engine will run the operation on Dask. If users just want to use Spark and Dask default configurations (normally local versions of these libraries), they can also pass a string.\n",
    "\n",
    "```python\n",
    "transform(df, fn, ..., engine=\"spark\")\n",
    "transform(df, fn, ..., engine=\"dask\")\n",
    "```\n",
    "\n",
    "If a pandas DataFrame is supplied as the input, it will be converted to that engine's brand of DataFrame before applying the operation. Below we see an example of Pandas DataFrame input and Dask DataFrame output. This is the same operation as illustrated above, note how we use the `\"dask\"` string to spin up a Dask client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 12:02:08,946 - distributed.diskutils - INFO - Found stale lock file and directory '/var/folders/9t/x99tw6714q97xfb86q1srbmc0000gn/T/dask-worker-space/worker-d7dffn7i', purging\n",
      "2022-08-18 12:02:08,947 - distributed.diskutils - INFO - Found stale lock file and directory '/var/folders/9t/x99tw6714q97xfb86q1srbmc0000gn/T/dask-worker-space/worker-7v650cup', purging\n",
      "2022-08-18 12:02:08,947 - distributed.diskutils - INFO - Found stale lock file and directory '/var/folders/9t/x99tw6714q97xfb86q1srbmc0000gn/T/dask-worker-space/worker-hpislbaj', purging\n",
      "2022-08-18 12:02:08,947 - distributed.diskutils - INFO - Found stale lock file and directory '/var/folders/9t/x99tw6714q97xfb86q1srbmc0000gn/T/dask-worker-space/worker-ap6f013v', purging\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.core.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x_1  x_2  predicted\n",
       "0    3    3       12.0\n",
       "0    4    3       13.0\n",
       "0    6    6       21.0\n",
       "0    6    6       21.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using transform to bring predict to dask execution\n",
    "result = transform(\n",
    "    df=input_df.copy(),\n",
    "    using=predict,\n",
    "    schema=\"*,predicted:double\",\n",
    "    params=dict(model=reg),\n",
    "    engine=\"dask\"                 # ensure you have dask installed before running -> pip install dask\n",
    ")\n",
    "\n",
    "# display results\n",
    "print(type(result))\n",
    "result.compute().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If no `engine` is supplied to transform, the function will be executed on pandas.\n",
    "\n",
    "While Fugue can convert Pandas DataFrames to Spark or Dask DataFrames, it will not perform the inverse of this, that is `transform()` will not output a Pandas DataFrame. It normally makes more sense to save the output data as a parquet file after transformations. Additionally users can use Spark's `toPandas()` or Dask's `compute()` if they want to convert their data to Pandas. Fugue prefers the user explicitly does this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type Hint Conversion\n",
    "\n",
    "In the previous section, we successfully displayed how Fugue can facilitate distributed execution by granting a Pandas based function with valid input and output types access to Spark or Dask engines. The `predict()` function we defined above accepted `pd.DataFrame` as input and `pd.DataFrame` as output. These type annotations are essentially used by Fugue as a kind of blueprint in order to allow Fugue to convert the data before the function is applied. For example, in the Spark ecosystem a DataFrame will be converted to multiple Pandas DataFrames.\n",
    "\n",
    "Fugue can also handle other DataFrame-like input and output types. Take the following function that sums up a whole row and returns one column. Note that if the value in the summed column is greater than 10, we drop the row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"a\": [1,2,3,4], \"b\": [1,2,3,4], \"c\": [1,2,3,4]})\n",
    "\n",
    "def add_row(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    A function that sums each row in a dataframe and drops the row\n",
    "    if the sum is greater than 10.\n",
    "    \"\"\"\n",
    "    df = df.assign(total=df.sum(axis=1))\n",
    "    df = df.loc[df[\"total\"] < 10]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be ran using `transform()` without passing an `engine`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b  c  total\n",
       "0  1  1  1      3\n",
       "1  2  2  2      6\n",
       "2  3  3  3      9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform(\n",
    "    df=df, \n",
    "    using=add_row, \n",
    "    schema=\"*,total:int\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This same logic can be represented in multiple ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Iterable, Any, Dict\n",
    "\n",
    "def add_row2(df: List[Dict[str,Any]]) -> List[Dict[str,Any]]:\n",
    "    \"\"\"\n",
    "    A function that sums each row in a dataframe and drops the row\n",
    "    if the sum is greater than 10.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for row in df:\n",
    "        row[\"total\"] = row[\"a\"] + row[\"b\"] + row[\"c\"]\n",
    "        if row[\"total\"] < 10:\n",
    "            result.append(row)\n",
    "    return result\n",
    "\n",
    "def add_row3(df: List[List[Any]]) -> Iterable[List[Any]]:\n",
    "    \"\"\"\n",
    "    A function that sums each row in a dataframe and drops the row\n",
    "    if the sum is greater than 10.\n",
    "    \"\"\"\n",
    "    for row in df:\n",
    "        row.append(sum(row))\n",
    "        if row[-1] < 10:\n",
    "            yield row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input type annotation tells Fugue what to convert the input data to before the function is applied whereas the output type annotation informs Fugue how to convert it back to a Pandas, Spark, or Dask DataFrame. Notice that these functions are not even dependent on pandas and can be tested easily. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'a': 1, 'b': 2, 'c': 3, 'total': 6}]\n",
      "[[1, 2, 3, 6]]\n"
     ]
    }
   ],
   "source": [
    "print(add_row2([{\"a\": 1, \"b\": 2, \"c\": 3}]))\n",
    "print(list(add_row3([[1,2,3]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is one of the core offerings of Fugue. **Testing code that uses Spark or Dask is hard because of the dependency on the hardware.** Even if running the tests locally, iteration speed is significantly slower than using pandas. This setup allows developers to unit test Python or pandas code, and bring it to Spark or Dask when ready.\n",
    "\n",
    "These definitions are compatible with `transform()` across all execution engines. For example, we can use `add_row2` with the Spark engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:=================================>                        (4 + 3) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-----+\n",
      "|  a|  b|  c|total|\n",
      "+---+---+---+-----+\n",
      "|  1|  1|  1|    3|\n",
      "|  2|  2|  2|    6|\n",
      "|  3|  3|  3|    9|\n",
      "+---+---+---+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "transform(\n",
    "    df=df, \n",
    "    using=add_row2, \n",
    "    schema=\"*,total:int\", \n",
    "    engine=spark\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a list of acceptable input and output types. They can be mixed and matched. There is no need to memorize them, in fact, a lot of users tend to just use a few of them. The point is that users can write their functions in the grammar of their choice.\n",
    "\n",
    "**Acceptable input DataFrame types**\n",
    "\n",
    "* `LocalDataFrame`, `pd.DataFrame`, `List[List[Any]]`, `Iterable[List[Any]]`, `EmptyAwareIterable[List[Any]]`, `List[Dict[str, Any]]`, `Iterable[Dict[str, Any]]`, `EmptyAwareIterable[Dict[str, Any]]`\n",
    "\n",
    "**Acceptable output DataFrame types**\n",
    "\n",
    "* `LocalDataFrame`, `pd.DataFrame`, `List[List[Any]]`, `Iterable[List[Any]]`, `EmptyAwareIterable[List[Any]]`, `List[Dict[str, Any]]`, `Iterable[Dict[str, Any]]`, `EmptyAwareIterable[Dict[str, Any]]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partitioning\n",
    "\n",
    "The input type conversion is not applied at the DataFrame level but rather on the partition level. If no partitions are supplied, the default engine partitions are used. To get a better clue of partitions, look at the following function that calculates the size of a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame\n",
    "df = pd.DataFrame({\"a\": [1,2,3,4], \"b\": [1,2,3,4], \"c\": [1,2,3,4]})\n",
    "\n",
    "def size(df: pd.DataFrame) -> Iterable[Dict[str,Any]]:\n",
    "    \"\"\"\n",
    "    Function that calculates the size of a DataFrame.\n",
    "    \"\"\"\n",
    "    yield {\"size\":df.shape[0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we run it on Dask using the `transform()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   size\n",
       "0     1\n",
       "0     1\n",
       "0     1\n",
       "0     1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform(\n",
    "    df=df, \n",
    "    using=size, \n",
    "    schema=\"size:int\", \n",
    "    engine=\"dask\"\n",
    "    ).compute().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results display 4 rows of data, each with a value of 1. This indicates that the `size()` function defined above, ran on 4 partitions of the data, each of which contained one row. This demonstrates that the type hint conversion happens on each partition. The concept of partitioning is important for distributed computing. When dealing with big data, it's more effective to find logically independent groups of data that can serve as the partitioning strategy. Take the following DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  col1  col2\n",
       "0    a     1\n",
       "1    a     2\n",
       "2    a     3\n",
       "3    b     4\n",
       "4    b     5\n",
       "5    b     6"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"col1\": [\"a\",\"a\",\"a\",\"b\",\"b\",\"b\"], \n",
    "                   \"col2\": [1,2,3,4,5,6]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to get the min and max values of `col2` for each group in `col1`. First, we define the logic for one group of data. Again, we take advantage of the type hint conversions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max(df:pd.DataFrame) -> List[Dict[str,Any]]:\n",
    "    \"\"\"\n",
    "    Calculates the min and max of a given column based\n",
    "    on the grouping of a separate column.\n",
    "    \"\"\"\n",
    "    return [{\"group\": df.iloc[0][\"col1\"], \n",
    "             \"max\": df['col2'].max(), \n",
    "             \"min\": df['col2'].min()}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can specify the partitioning strategy on the `transform()` function by doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  group  max  min\n",
       "0     a    3    1\n",
       "1     b    6    4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform(\n",
    "    df=df, \n",
    "    using=min_max, \n",
    "    schema=\"group:str, max:int, min:int\",\n",
    "    partition={\"by\": \"col1\"}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On pandas, the `partition-transform` semantic is close to a `groupby-apply`. The difference is that the `partition-transform` paradigm also extends to distributed computing where we control the movement of the physical location of the data. Again, the expression above will also work on Spark and Dask by supplying the engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  group  max  min\n",
       "0     b    6    4\n",
       "0     a    3    1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform(\n",
    "    df=df,\n",
    "    using=min_max,\n",
    "    schema=\"group:str,max:int,min:int\",\n",
    "    partition={\"by\": \"col1\"},\n",
    "    engine=\"dask\"\n",
    "    ).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Presort\n",
    "\n",
    "During the partition operation, we can specify a `presort` so that the data comes in sorted before the function is applied. For example, we can get the top 2 rows of each group using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  col1  col2\n",
       "0    a     3\n",
       "1    a     2\n",
       "2    b     6\n",
       "3    b     5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def top_two(df:List[Dict[str,Any]]) -> Iterable[Dict[str,Any]]:\n",
    "    \"\"\"\n",
    "    Function that returns the top 2 rows of an iterable.\n",
    "    \"\"\"\n",
    "    n = 0\n",
    "    while n < 2:\n",
    "        yield df[n]\n",
    "        n = n + 1\n",
    "\n",
    "transform(\n",
    "    df=df, \n",
    "    using=top_two, \n",
    "    schema=\"*\", \n",
    "    partition={\"by\":\"col1\", \"presort\": \"col2 desc\"}\n",
    "    )        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition Validation\n",
    "\n",
    "In order for the functions that we defined above to behave correctly, we required the data to be partitioned or sorted. To ensure that we have configured the data correctly before passing it to our functions, we can define a partition validation check that instructs Fugue to throw an error if partitioning or presorting have not been aptly applied. Note the comments above the function defined below which will be read and applied. Even if Fugue is not used, they serve as helpful comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  col1  col2\n",
       "0    a     3\n",
       "1    a     2\n",
       "2    b     6\n",
       "3    b     5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# partitionby_has: col1\n",
    "# presort_is: col2 desc\n",
    "def top_two(df:List[Dict[str,Any]]) -> Iterable[Dict[str,Any]]:\n",
    "    \"\"\"\n",
    "    Function that returns the top 2 rows of an iterable.\n",
    "    \"\"\"\n",
    "    n = 0\n",
    "    while n < 2:\n",
    "        yield df[n]\n",
    "        n = n + 1\n",
    "\n",
    "transform(\n",
    "    df=df, \n",
    "    using=top_two, \n",
    "    schema=\"*\", \n",
    "    partition={\"by\":\"col1\", \"presort\": \"col2 desc\"}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code snippet exhibits a function operating on data that has been correctly paritioned and/or presorted. Now take a look at what happens if we don't apply these steps correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "required presort key col2 is not in presort of PartitionSpec(num='0', by=['col1'], presort='')\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    transform(\n",
    "        df=df, \n",
    "        using=top_two, \n",
    "        schema=\"*\", \n",
    "        partition={\"by\":\"col1\"}\n",
    "        )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitioning Strategies (Advanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Fugue also offers a number of other partitioning strategies that can be used aside from the column level strategy described above. See below for a brief summary of these strategies. Also, make sure to check out [partitioning](advanced/partition.ipynb) for further information.\n",
    "\n",
    "**Algo**\n",
    "* even - enforces an even number of items per partition\n",
    "* rand - randomly shuffles data\n",
    "* hash - uses hashing to partition the data (similar to Spark default)\n",
    "\n",
    "**Num**\n",
    "* A number of partitions can be supplied as the partitioning strategy. Note that this startegy will not work for the pandas-based engine.\n",
    "\n",
    "These strategies can also be used with `presort`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  col1  col2\n",
       "0    a     1\n",
       "0    a     2\n",
       "0    a     3\n",
       "0    b     4\n",
       "0    b     5\n",
       "0    b     6"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def no_op(df:List[Dict[str,Any]]) -> Iterable[Dict[str,Any]]:\n",
    "    \"\"\"\n",
    "    Function that returns the first row of an iterable.\n",
    "    \"\"\"\n",
    "    yield df[0]\n",
    "\n",
    "# by number\n",
    "transform(\n",
    "    df=df, \n",
    "    using=no_op, \n",
    "    schema=\"*\", \n",
    "    partition={\"num\":4}, \n",
    "    engine=\"dask\"\n",
    "    ).compute()\n",
    "\n",
    "# by algorithm\n",
    "transform(\n",
    "    df=df, \n",
    "    using=no_op, \n",
    "    schema=\"*\", \n",
    "    partition={\"algo\":\"even\"}, \n",
    "    engine=\"dask\"\n",
    "    ).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that `transform()` runs on each partition of data. When using the pandas-based engine, the whole DataFrame is treated as one partition. For example, if you are normalizing a column of data, it will be applied on a per partition basis.\n",
    "\n",
    "If you need to perform an operation that requires global max/mean/min, then Fugue has a more advanced interface for that called `FugueWorkflow`, or you can use the native Spark/Dask operations after a `transform()` call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema\n",
    "\n",
    "We have seen a couple of `transform()` calls by now and each of them has had the `schema` passed in. The schema is a requirement for Spark, and heavily recommended for Dask. When data lives across multiple machines, schema inference can be very expensive, and take long. Also, operations can be silently inconsistent. \n",
    "\n",
    "Fugue enforces best practices so that code can run effectively at scale. Here we see how to use Fugue's representation, which is minimal compared to Spark's. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Fugue project has a utility called `triad`, which contains the `Schema` class. In practice, you will just need to interact with the string representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from triad.collections.schema import Schema\n",
    "\n",
    "s = Schema(\"a:int, b:str\")\n",
    "s == \"a:int,b:str\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this section we create a DataFrame to use that will be used throughout the examples provided below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"a\": [1,2,3], \"b\": [1,2,3], \"c\": [1,2,3]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding a column**\n",
    "\n",
    "When using the `transform()`, the `*` in a schema expression means all existing columns. From there we can add new columns by adding `\",col:type\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>new_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b  c  new_col\n",
       "0  1  1  1        2\n",
       "1  2  2  2        3\n",
       "2  3  3  3        4"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_col(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function that creates a column with a value of column a + 1.\n",
    "    \"\"\"\n",
    "    return df.assign(new_col=df[\"a\"] + 1)\n",
    "\n",
    "transform(\n",
    "    df=df, \n",
    "    using=add_col, \n",
    "    schema=\"*,new_col:int\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entirely new schema**\n",
    "\n",
    "There is no need to use the `*` operation. We can just specify all columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x\n",
       "0  1\n",
       "1  2\n",
       "2  3"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def new_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function that creates a new DataFrame.\n",
    "    \"\"\"\n",
    "    return pd.DataFrame({\"x\": [1,2,3]})\n",
    "\n",
    "transform(\n",
    "    df=df, \n",
    "    using=new_df, \n",
    "    schema=\"x:int\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dropping Columns**\n",
    "\n",
    "To drop a column, use `-col` without `\",\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  c\n",
       "0  1  1\n",
       "1  2  2\n",
       "2  3  3"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def drop_col(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    A function used to drop a column labelled 'b'.\n",
    "    \"\"\"\n",
    "    return df.drop(\"b\", axis=1)\n",
    "\n",
    "transform(\n",
    "    df=df, \n",
    "    using=drop_col, \n",
    "    schema=\"*-b\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Altering Types**\n",
    "\n",
    "If a column is remaining but the type is being altered, use `+col:type`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2a</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3a</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    a  b  c\n",
       "0  1a  1  1\n",
       "1  2a  2  2\n",
       "2  3a  3  3"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def alter_col(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function that changes column a to string.\n",
    "    \"\"\"\n",
    "    return df.assign(a=df['a'].astype(\"str\")+\"a\")\n",
    "\n",
    "transform(\n",
    "    df=df, \n",
    "    using=alter_col, \n",
    "    schema=\"*+a:str\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop if Present**\n",
    "\n",
    "Use `~` to drop a column from the result if it is present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  c\n",
       "0  1  1\n",
       "1  2  2\n",
       "2  3  3"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def no_op(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    A function that returns its input.\n",
    "    \"\"\"\n",
    "    return df\n",
    "\n",
    "transform(\n",
    "    df=df, \n",
    "    using=no_op, \n",
    "    schema=\"*~b\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Schema Result Mismatch**\n",
    "\n",
    "If the `transform()` output has columns not in the defined schema, they will not be returned.\n",
    "\n",
    "If the `transform()` output has an inconsistent type with the defined schema, it will be coerced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a\n",
       "0  1.0\n",
       "1  2.0\n",
       "2  3.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def no_op(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    A function that returns its input.\n",
    "    \"\"\"\n",
    "    return df\n",
    "\n",
    "transform(\n",
    "    df=df, \n",
    "    using=no_op, \n",
    "    schema=\"a:float\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining Schema**\n",
    "\n",
    "There is more than one way to define the schema, in the above examples we supplied the schema as an argument in the `Transform()` function. The schema can also be supplied on the function as a comment similar to the partition validation described earlier in this chapter. If done this way, the schema should not be supplied to the `transform()` function. \n",
    "\n",
    "Fugue has no preference. The advantage of having schema is a string is that it can programmatically be manipulated while the comment can't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a\n",
       "0  1\n",
       "1  2\n",
       "2  3"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# schema: a:int\n",
    "def no_op(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    A function that returns its input.\n",
    "    \"\"\"\n",
    "    return df\n",
    "\n",
    "transform(\n",
    "    df=df, \n",
    "    using=no_op\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File IO with `transform()`\n",
    "\n",
    "**Input file**\n",
    "\n",
    "The `transform()` function also supports loading parquet files from source. With this, users don't need to worry about passing a Pandas or Spark DataFrame to `transform()`. It will be loaded by the `engine`.\n",
    "\n",
    "**Output file**\n",
    "\n",
    "Users can also write out the result of the `transform()` operation as a parquet file. This can be done by providing a `save_path`.\n",
    "\n",
    "Only parquet files are supported because CSVs often have additional configuration that make it harder to deal with. Parquet files are also a best practice for big data because they are partitioned and hold schema information.\n",
    "\n",
    "Absolute paths are also a best practice for big data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"a\": [1,2,3], \"b\": [1,2,3], \"c\": [1,2,3]})\n",
    "df.to_parquet(\"/tmp/df.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  c\n",
       "0  1  1\n",
       "1  2  2\n",
       "2  3  3"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def drop_col(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    A function that drops a column labelled 'b'.\n",
    "    \"\"\"\n",
    "    return df.drop(\"b\", axis=1)\n",
    "\n",
    "transform(\n",
    "    df=\"/tmp/df.parquet\",\n",
    "    using=drop_col,\n",
    "    schema=\"*-b\",\n",
    "    engine=spark,\n",
    "    save_path=\"/tmp/processed.parquet\"\n",
    "    )\n",
    "\n",
    "pd.read_parquet(\"/tmp/processed.parquet/\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This expression makes it easy for users to toggle between running pandas with sampled data and using Spark or Dask on the full dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The Fugue `transform()` function is the simplest interface for Fugue. It handles the execution of one function across Pandas, Spark, and Dask. Most users can easily adopt this minimal wrapper to parallelize existing code that they have already written. For end-to-end workflows, see [FugueWorkflow](/beginner/decoupling_logic_and_execution.html#transform-versus-fugueworkflow)\n",
    "\n",
    "For any questions, free free to reach out on [Slack](http://slack.fugue.ai)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('3.7.0')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4a179fa03a25f29299f81a56c7e3b211fb522811d9fd99af4f126fb7978a76dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
