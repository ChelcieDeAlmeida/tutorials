{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading text files\n",
    "\n",
    "`fugue` can read text files natively via `load` or by dropping into an execution engine\n",
    "\n",
    "You might find it useful to use the execution engine directly for loading non-standard files or files that are not natively supported by `fugue`\n",
    "\n",
    "We'll demonstrate `pandas`, `duckdb` & `dask` here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import textwrap\n",
    "import typing\n",
    "\n",
    "import duckdb\n",
    "from fugue import DataFrame\n",
    "from fugue import ExecutionEngine\n",
    "from fugue import FugueWorkflow\n",
    "from fugue import NativeExecutionEngine\n",
    "from fugue_dask import DaskExecutionEngine\n",
    "from fugue_duckdb import DuckExecutionEngine\n",
    "from fugue_sql import fsql\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_temporary_file(\n",
    "    _content: str, suffix: str, prefix: str=\"fugue_example_\"\n",
    ") -> str:\n",
    "    text_file = tempfile.NamedTemporaryFile(\n",
    "        suffix=suffix, prefix=prefix, delete=False\n",
    "    )\n",
    "    text_file.write(_content)\n",
    "    return text_file.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: /tmp/*.csv\r\n"
     ]
    }
   ],
   "source": [
    "!rm /tmp/*.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a sample text file ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = textwrap.dedent(\"\"\"\\\n",
    "    a,b,c\n",
    "    1,2,3\n",
    "    1,2,3\"\"\"\n",
    ").encode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can read it natively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PandasDataFrame\n",
      "a:str|b:str|c:str\n",
      "-----+-----+-----\n",
      "1    |2    |3    \n",
      "1    |2    |3    \n",
      "Total count: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_filepath = create_temporary_file(content, suffix=\".csv\")\n",
    "\n",
    "dag = FugueWorkflow()\n",
    "df = dag.load(csv_filepath, header=True)\n",
    "df.show()\n",
    "dag.run(engine=\"pandas\")\n",
    "\n",
    "os.unlink(csv_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can read multiple files using a wildcard `*` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PandasDataFrame\n",
      "a:str|b:str|c:str\n",
      "-----+-----+-----\n",
      "1    |2    |3    \n",
      "1    |2    |3    \n",
      "1    |2    |3    \n",
      "1    |2    |3    \n",
      "Total count: 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_filepath_1 = create_temporary_file(content, suffix=\".csv\")\n",
    "csv_filepath_2 = create_temporary_file(content, suffix=\".csv\")\n",
    "csv_filepath_wildcard = \"/tmp/fugue_example_*.csv\"\n",
    "\n",
    "dag = FugueWorkflow()\n",
    "df = dag.load(csv_filepath_wildcard, header=True)\n",
    "df.show()\n",
    "dag.run(engine=\"pandas\")\n",
    "\n",
    "os.unlink(csv_filepath_1)\n",
    "os.unlink(csv_filepath_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can use the execution engine directly if your input file is non-standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = textwrap.dedent(\"\"\"\\\n",
    "    date: 2022-10-17\n",
    "    columns: a,b,c\n",
    "    1,2,3\n",
    "    1,2,3\"\"\"\n",
    ").encode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_header(filepath: str) -> typing.List[str]:\n",
    "    row_1 = pd.read_csv(filepath, skiprows=1, nrows=0).columns\n",
    "    header = [row_1[0].replace(\"columns: \", \"\"), *row_1[1:]]\n",
    "    return header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PandasDataFrame\n",
      "a:str                                                                                   |b:str|c:str\n",
      "----------------------------------------------------------------------------------------+-----+-----\n",
      "columns: a                                                                              |b    |c    \n",
      "1                                                                                       |2    |3    \n",
      "1                                                                                       |2    |3    \n",
      "Total count: 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def read_text_file(filepath: str) -> pd.DataFrame:\n",
    "    headers = read_header(filepath)\n",
    "    return pd.read_csv(filepath, skiprows=1, names=headers)\n",
    "\n",
    "csv_filepath = create_temporary_file(content, suffix=\".csv\")\n",
    "\n",
    "dag = FugueWorkflow()\n",
    "df = dag.create(read_text_file, params={\"filepath\": csv_filepath})\n",
    "df.show()\n",
    "dag.run(engine=\"pandas\")\n",
    "\n",
    "os.unlink(csv_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the `fugue` `NativeExecutionEngine` which wraps `pandas` under the hood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PandasDataFrame\n",
      "a:str|b:str|c:str\n",
      "-----+-----+-----\n",
      "1    |2    |3    \n",
      "1    |2    |3    \n",
      "Total count: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def read_text_file(filepath: str) -> pd.DataFrame:\n",
    "    headers = read_header(filepath)\n",
    "    engine = NativeExecutionEngine()\n",
    "    return engine.load_df(filepath, header=True, skiprows=1, names=headers)\n",
    "\n",
    "csv_filepath = create_temporary_file(content, suffix=\".csv\")\n",
    "\n",
    "dag = FugueWorkflow()\n",
    "df = dag.create(read_text_file, params={\"filepath\": csv_filepath})\n",
    "df.show()\n",
    "dag.run(engine=\"pandas\")\n",
    "\n",
    "os.unlink(csv_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `duckdb`\n",
    "\n",
    "> **Note:** `skip` & `columns` for `DuckExecutionEngine` correspond to `skiprows` & `names` for `pandas.read_csv` as `duckdb` `csv` has different conventions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DuckDataFrame\n",
      "a:str|b:str|c:str\n",
      "-----+-----+-----\n",
      "1    |2    |3    \n",
      "1    |2    |3    \n",
      "Total count: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def read_text_file(filepath: str) -> DataFrame:\n",
    "    headers = read_header(filepath)\n",
    "    engine = DuckExecutionEngine()\n",
    "    return engine.load_df(csv_filepath, skip=2, columns=headers)\n",
    "\n",
    "csv_filepath = create_temporary_file(content, suffix=\".csv\")\n",
    "\n",
    "dag = FugueWorkflow()\n",
    "df = dag.create(read_text_file, params={\"filepath\": csv_filepath})\n",
    "df.show()\n",
    "dag.run(engine=\"duck\")\n",
    "\n",
    "os.unlink(csv_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `dask`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-19 20:20:17,548 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-60sqobj8', purging\n",
      "2022-10-19 20:20:17,548 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-bed3uf74', purging\n",
      "2022-10-19 20:20:17,548 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-4pnbyqsj', purging\n",
      "2022-10-19 20:20:17,549 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-y_22uck1', purging\n",
      "2022-10-19 20:20:17,549 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-be63tyrp', purging\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DaskDataFrame\n",
      "a:str|b:str|c:str\n",
      "-----+-----+-----\n",
      "1    |2    |3    \n",
      "1    |2    |3    \n",
      "Total count: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def read_text_file(filepath: str) -> DataFrame:\n",
    "    headers = read_header(filepath)\n",
    "    engine = DaskExecutionEngine()\n",
    "    return engine.load_df(csv_filepath, header=True, skiprows=1, names=headers)\n",
    "\n",
    "csv_filepath = create_temporary_file(content, suffix=\".csv\")\n",
    "\n",
    "dag = FugueWorkflow()\n",
    "df = dag.create(read_text_file, params={\"filepath\": csv_filepath})\n",
    "df.show()\n",
    "dag.run(engine=\"dask\")\n",
    "\n",
    "os.unlink(csv_filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
